{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a11fbd4",
   "metadata": {
    "papermill": {
     "duration": 0.007852,
     "end_time": "2023-05-29T01:33:35.129382",
     "exception": false,
     "start_time": "2023-05-29T01:33:35.121530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this inference notebook I show that with the correct data pre-processing, model architecture and training setup an LSTM model can achieve the same performance as the current top performing Graph based models.\n",
    "\n",
    "This notebook is based on the notebook originally published with LSTM training and inference: [3 LSTMs; with Data Picking and Shifting](https://www.kaggle.com/code/seungmoklee/3-lstms-with-data-picking-and-shifting). So if you like my notebooks don't forget the work that it is based!\n",
    "\n",
    "This Inference notebook is for the largest part the same. It doesn't use the shifting as applied in the original work, it is based on only using 96 pulses and only 6 features.\n",
    "It does ensemble 3 models but they are from the same training run (just different epochs).\n",
    "\n",
    "Combining models from different model trainings with slightly different hyperparameters will very likely further increase the score. Increasing the number of bins and using more data for training is another way to increase the score of the models. Consider the Inference and Training notebooks a starting point to explore that yourself!\n",
    "\n",
    "The training notebook for these models can be found [here](https://www.kaggle.com/code/rsmits/tensorflow-lstm-model-training-tpu). Note that I performed training on my local laptop (32GB RAM / NVidia 3070). For local training I loaded the files for 70 batches into RAM. The training notebook is equal to my local setup with the change that it loads multiple rounds of training data.\n",
    "\n",
    "In the training notebook I will further explain what the differences are and how I improved the achieved score.\n",
    "\n",
    "I hope you enjoy this notebook and if you do please give it an upvote :-)\n",
    "\n",
    "!! Update in Latest Version: In the comments it was mentioned that using model files from a TPU training caused an error when trying to load the model. I've updated the load_model() with compile = False. This solves the error. Nothing else has changed in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9728461d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:35.144745Z",
     "iopub.status.busy": "2023-05-29T01:33:35.144218Z",
     "iopub.status.idle": "2023-05-29T01:33:39.541882Z",
     "shell.execute_reply": "2023-05-29T01:33:39.540790Z"
    },
    "papermill": {
     "duration": 4.408456,
     "end_time": "2023-05-29T01:33:39.544630",
     "exception": false,
     "start_time": "2023-05-29T01:33:35.136174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import gc\n",
    "import os\n",
    "import multiprocessing\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d212b0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:39.560241Z",
     "iopub.status.busy": "2023-05-29T01:33:39.559032Z",
     "iopub.status.idle": "2023-05-29T01:33:39.565163Z",
     "shell.execute_reply": "2023-05-29T01:33:39.564307Z"
    },
    "papermill": {
     "duration": 0.016014,
     "end_time": "2023-05-29T01:33:39.567303",
     "exception": false,
     "start_time": "2023-05-29T01:33:39.551289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directories and constants\n",
    "home_dir = \"/kaggle/input/icecube-neutrinos-in-deep-ice/\"\n",
    "test_format = home_dir + 'test/batch_{batch_id:d}.parquet'\n",
    "model_home = \"/kaggle/input/lstmmodels/\"\n",
    "\n",
    "# Model(s)\n",
    "model_names = [\"tpu_pp96_n7_bin24_batch8192_epoch50.h5\",\"tpu_pp96_n7_bin24_batch8192_epoch55.h5\",\"tpu_pp96_n7_bin24_batch8192_epoch69.h5\"]\n",
    "model_weights = np.array([0.3,0.4,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1c9b6",
   "metadata": {
    "papermill": {
     "duration": 0.006143,
     "end_time": "2023-05-29T01:33:39.580049",
     "exception": false,
     "start_time": "2023-05-29T01:33:39.573906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e717fefc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:39.594234Z",
     "iopub.status.busy": "2023-05-29T01:33:39.593440Z",
     "iopub.status.idle": "2023-05-29T01:33:58.098132Z",
     "shell.execute_reply": "2023-05-29T01:33:58.097098Z"
    },
    "papermill": {
     "duration": 18.514243,
     "end_time": "2023-05-29T01:33:58.100553",
     "exception": false,
     "start_time": "2023-05-29T01:33:39.586310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Model File: tpu_pp96_n7_bin24_batch8192_epoch50.h5\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 96, 7)]           0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 96, 7)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 96, 384)           231552    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 96, 384)           665856    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 384)               665856    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 576)               148032    \n",
      "=================================================================\n",
      "Total params: 1,809,856\n",
      "Trainable params: 1,809,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "========== Model File: tpu_pp96_n7_bin24_batch8192_epoch55.h5\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 96, 7)]           0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 96, 7)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 96, 384)           231552    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 96, 384)           665856    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 384)               665856    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 576)               148032    \n",
      "=================================================================\n",
      "Total params: 1,809,856\n",
      "Trainable params: 1,809,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "========== Model File: tpu_pp96_n7_bin24_batch8192_epoch69.h5\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 96, 7)]           0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 96, 7)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 96, 384)           231552    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 96, 384)           665856    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 384)               665856    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 576)               148032    \n",
      "=================================================================\n",
      "Total params: 1,809,856\n",
      "Trainable params: 1,809,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "==== Model Parameters\n",
      "Bin Numbers: 24\n",
      "Maximum Pulse Count: 96\n",
      "Features Count: 7\n"
     ]
    }
   ],
   "source": [
    "# Load Models\n",
    "models = []\n",
    "for model_name in model_names:\n",
    "    print(f'\\n========== Model File: {model_name}')\n",
    "    \n",
    "    # Load Model\n",
    "    model_path = model_home + model_name\n",
    "    model = tf.keras.models.load_model(model_path, compile = False)\n",
    "    models.append(model)      \n",
    "    \n",
    "    # Model summary\n",
    "    model.summary()\n",
    "    \n",
    "# Get Model Parameters\n",
    "pulse_count = model.inputs[0].shape[1]\n",
    "feature_count = model.inputs[0].shape[2]\n",
    "output_bins = model.layers[-1].weights[0].shape[-1]\n",
    "bin_num = int(np.sqrt(output_bins))\n",
    "\n",
    "# Model Parameter Summary\n",
    "print(\"\\n==== Model Parameters\")\n",
    "print(f\"Bin Numbers: {bin_num}\")\n",
    "print(f\"Maximum Pulse Count: {pulse_count}\")\n",
    "print(f\"Features Count: {feature_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11bb8c",
   "metadata": {
    "papermill": {
     "duration": 0.00661,
     "end_time": "2023-05-29T01:33:58.114273",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.107663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Detector Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee7fe68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:58.129192Z",
     "iopub.status.busy": "2023-05-29T01:33:58.128861Z",
     "iopub.status.idle": "2023-05-29T01:33:58.153716Z",
     "shell.execute_reply": "2023-05-29T01:33:58.152636Z"
    },
    "papermill": {
     "duration": 0.035288,
     "end_time": "2023-05-29T01:33:58.156362",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.121074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time valid length: 6199.700247193777 ns\n"
     ]
    }
   ],
   "source": [
    "# Load sensor_geometry\n",
    "sensor_geometry_df = pd.read_csv(home_dir + \"sensor_geometry.csv\")\n",
    "\n",
    "# Get Sensor Information\n",
    "sensor_x = sensor_geometry_df.x\n",
    "sensor_y = sensor_geometry_df.y\n",
    "sensor_z = sensor_geometry_df.z\n",
    "\n",
    "# Detector constants\n",
    "c_const = 0.299792458  # speed of light [m/ns]\n",
    "\n",
    "# Sensor Min / Max Coordinates\n",
    "x_min = sensor_x.min()\n",
    "x_max = sensor_x.max()\n",
    "y_min = sensor_y.min()\n",
    "y_max = sensor_y.max()\n",
    "z_min = sensor_z.min()\n",
    "z_max = sensor_z.max()\n",
    "\n",
    "detector_length = np.sqrt((x_max - x_min)**2 + (y_max - y_min)**2 + (z_max - z_min)**2)\n",
    "t_valid_length = detector_length / c_const\n",
    "\n",
    "print(f\"time valid length: {t_valid_length} ns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265ce6d",
   "metadata": {
    "papermill": {
     "duration": 0.006725,
     "end_time": "2023-05-29T01:33:58.170204",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.163479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Angle encoding edges\n",
    "\n",
    "- It is efficient to train the model by classification task, initially.\n",
    "- azimuth and zenith are independent\n",
    "- azimuth distribution is flat and zenith distribution is sinusoidal.\n",
    "  - Flat on the spherical surface\n",
    "  - $\\phi > \\pi$ events are a little bit rarer than $\\phi < \\pi$ events, (maybe) because of the neutrino attenuation by earth.\n",
    "- So, the uniform bin is used for azimuth, and $\\left| \\cos \\right|$ bin is used for zenith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6e8b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:58.185057Z",
     "iopub.status.busy": "2023-05-29T01:33:58.184734Z",
     "iopub.status.idle": "2023-05-29T01:33:58.194132Z",
     "shell.execute_reply": "2023-05-29T01:33:58.193164Z"
    },
    "papermill": {
     "duration": 0.019498,
     "end_time": "2023-05-29T01:33:58.196550",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.177052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.26179939 0.52359878 0.78539816 1.04719755 1.30899694\n",
      " 1.57079633 1.83259571 2.0943951  2.35619449 2.61799388 2.87979327\n",
      " 3.14159265 3.40339204 3.66519143 3.92699082 4.1887902  4.45058959\n",
      " 4.71238898 4.97418837 5.23598776 5.49778714 5.75958653 6.02138592\n",
      " 6.28318531]\n",
      "[0.         0.41113786 0.58568554 0.72273425 0.84106867 0.94796974\n",
      " 1.04719755 1.1410209  1.23095942 1.31811607 1.40334825 1.48736624\n",
      " 1.57079633 1.65422641 1.73824441 1.82347658 1.91063324 2.00057176\n",
      " 2.0943951  2.19362291 2.30052398 2.41885841 2.55590711 2.73045479\n",
      " 3.14159265]\n"
     ]
    }
   ],
   "source": [
    "# Create Azimuth Edges\n",
    "azimuth_edges = np.linspace(0, 2 * np.pi, bin_num + 1)\n",
    "print(azimuth_edges)\n",
    "\n",
    "# Create Zenith Edges\n",
    "zenith_edges = []\n",
    "zenith_edges.append(0)\n",
    "for bin_idx in range(1, bin_num):\n",
    "    zenith_edges.append(np.arccos(np.cos(zenith_edges[-1]) - 2 / (bin_num)))\n",
    "zenith_edges.append(np.pi)\n",
    "zenith_edges = np.array(zenith_edges)\n",
    "print(zenith_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34838c82",
   "metadata": {
    "papermill": {
     "duration": 0.006746,
     "end_time": "2023-05-29T01:33:58.210299",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.203553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define a function converts from prediction to angles\n",
    "\n",
    "- Calculation of the mean-vector in a bin $\\theta \\in ( \\theta_0, \\theta_1 )$ and $\\phi \\in ( \\phi_0, \\phi_1 )$\n",
    "  - $\\vec{r} \\left( \\theta, ~ \\phi \\right) = \\left< \\sin \\theta \\cos \\phi, ~ \\sin \\theta \\sin \\phi, ~ \\cos \\theta \\right>$\n",
    "  - $\\bar{\\vec{r}} = \\frac{ \\int_{\\theta_{0}}^{\\theta_{1}} \\int_{\\phi_0}^{\\phi_1} \\vec{r} \\left( \\theta, ~ \\phi \\right) \\sin \\theta \\,d\\phi \\,d\\theta }{ \\int_{\\theta_{0}}^{\\theta_{1}} \\int_{\\phi_0}^{\\phi_1} 1 \\sin \\theta \\,d\\phi \\,d\\theta }$\n",
    "  - $ \\int_{\\theta_{0}}^{\\theta_{1}} \\int_{\\phi_0}^{\\phi_1} 1 \\sin \\theta \\,d\\phi \\,d\\theta = \\left( \\phi_1 - \\phi_0 \\right) \\left( \\cos \\theta_0 - \\cos \\theta_1 \\right)$\n",
    "  - $\n",
    "\\int_{\\theta_{0}}^{\\theta_{1}} \\int_{\\phi_0}^{\\phi_1} {r}_{x} \\left( \\theta, ~ \\phi \\right) \\sin \\theta \\,d\\phi \\,d\\theta = \n",
    "\\int_{\\theta_{0}}^{\\theta_{1}} \\int_{\\phi_0}^{\\phi_1} \\sin^2 \\theta \\cos \\phi \\,d\\phi \\,d\\theta = \n",
    "\\left( \\sin \\phi_1 - \\sin \\phi_0 \\right) \\left( \\frac{\\theta_1 - \\theta_0}{2} - \\frac{\\sin 2 \\theta_1 - \\sin 2 \\theta_0}{4} \\right)\n",
    "$\n",
    "  - $\n",
    "\\int_{\\theta_{0}}^{\\theta_{1}} \\int_{\\phi_0}^{\\phi_1} {r}_{y} \\left( \\theta, ~ \\phi \\right) \\sin \\theta \\,d\\phi \\,d\\theta = \n",
    "\\int_{\\theta_{0}}^{\\theta_{1}} \\int_{\\phi_0}^{\\phi_1} \\sin^2 \\theta \\sin \\phi \\,d\\phi \\,d\\theta = \n",
    "\\left( \\cos \\phi_0 - \\cos \\phi_1 \\right) \\left( \\frac{\\theta_1 - \\theta_0}{2} - \\frac{\\sin 2 \\theta_1 - \\sin 2 \\theta_0}{4} \\right)\n",
    "$\n",
    "  - $\n",
    "\\int_{\\theta_{0}}^{\\theta_{1}} \\int_{\\phi_0}^{\\phi_1} {r}_{z} \\left( \\theta, ~ \\phi \\right) \\sin \\theta \\,d\\phi \\,d\\theta = \n",
    "\\int_{\\theta_{0}}^{\\theta_{1}} \\int_{\\phi_0}^{\\phi_1} \\sin \\theta \\cos \\theta \\,d\\phi \\,d\\theta = \n",
    "\\left( \\phi_1 - \\phi_0 \\right) \\left( \\frac{\\cos 2 \\theta_0 - \\cos 2 \\theta_1}{4} \\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44555483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:58.226573Z",
     "iopub.status.busy": "2023-05-29T01:33:58.224898Z",
     "iopub.status.idle": "2023-05-29T01:33:58.240371Z",
     "shell.execute_reply": "2023-05-29T01:33:58.239465Z"
    },
    "papermill": {
     "duration": 0.025524,
     "end_time": "2023-05-29T01:33:58.242627",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.217103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "angle_bin_zenith0 = np.tile(zenith_edges[:-1], bin_num)\n",
    "angle_bin_zenith1 = np.tile(zenith_edges[1:], bin_num)\n",
    "angle_bin_azimuth0 = np.repeat(azimuth_edges[:-1], bin_num)\n",
    "angle_bin_azimuth1 = np.repeat(azimuth_edges[1:], bin_num)\n",
    "\n",
    "angle_bin_area = (angle_bin_azimuth1 - angle_bin_azimuth0) * (np.cos(angle_bin_zenith0) - np.cos(angle_bin_zenith1))\n",
    "angle_bin_vector_sum_x = (np.sin(angle_bin_azimuth1) - np.sin(angle_bin_azimuth0)) * ((angle_bin_zenith1 - angle_bin_zenith0) / 2 - (np.sin(2 * angle_bin_zenith1) - np.sin(2 * angle_bin_zenith0)) / 4)\n",
    "angle_bin_vector_sum_y = (np.cos(angle_bin_azimuth0) - np.cos(angle_bin_azimuth1)) * ((angle_bin_zenith1 - angle_bin_zenith0) / 2 - (np.sin(2 * angle_bin_zenith1) - np.sin(2 * angle_bin_zenith0)) / 4)\n",
    "angle_bin_vector_sum_z = (angle_bin_azimuth1 - angle_bin_azimuth0) * ((np.cos(2 * angle_bin_zenith0) - np.cos(2 * angle_bin_zenith1)) / 4)\n",
    "\n",
    "angle_bin_vector_mean_x = angle_bin_vector_sum_x / angle_bin_area\n",
    "angle_bin_vector_mean_y = angle_bin_vector_sum_y / angle_bin_area\n",
    "angle_bin_vector_mean_z = angle_bin_vector_sum_z / angle_bin_area\n",
    "\n",
    "angle_bin_vector = np.zeros((1, bin_num * bin_num, 3))\n",
    "angle_bin_vector[:, :, 0] = angle_bin_vector_mean_x\n",
    "angle_bin_vector[:, :, 1] = angle_bin_vector_mean_y\n",
    "angle_bin_vector[:, :, 2] = angle_bin_vector_mean_z\n",
    "\n",
    "angle_bin_vector_unit = angle_bin_vector[0].copy()\n",
    "angle_bin_vector_unit /= np.sqrt((angle_bin_vector_unit**2).sum(axis=1).reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92646a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:58.258324Z",
     "iopub.status.busy": "2023-05-29T01:33:58.258045Z",
     "iopub.status.idle": "2023-05-29T01:33:58.266367Z",
     "shell.execute_reply": "2023-05-29T01:33:58.265289Z"
    },
    "papermill": {
     "duration": 0.019532,
     "end_time": "2023-05-29T01:33:58.268926",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.249394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_to_angle(pred, epsilon = 1e-8):\n",
    "    # Convert prediction\n",
    "    pred_vector = (pred.reshape((-1, bin_num**2, 1)) * angle_bin_vector).sum(axis = 1)\n",
    "    \n",
    "    # Normalize\n",
    "    pred_vector_norm = np.sqrt((pred_vector**2).sum(axis = 1))\n",
    "    mask = pred_vector_norm < epsilon\n",
    "    pred_vector_norm[mask] = 1\n",
    "    \n",
    "    # Assign <1, 0, 0> to very small vectors (badly predicted)\n",
    "    pred_vector /= pred_vector_norm.reshape((-1, 1))\n",
    "    pred_vector[mask] = np.array([1., 0., 0.])\n",
    "    \n",
    "    # Convert to angle\n",
    "    azimuth = np.arctan2(pred_vector[:, 1], pred_vector[:, 0])\n",
    "    azimuth[azimuth < 0] += 2 * np.pi\n",
    "    zenith = np.arccos(pred_vector[:, 2])\n",
    "    \n",
    "    # Mask bad norm predictions as 0, 0\n",
    "    azimuth[mask] = 0.\n",
    "    zenith[mask] = 0.\n",
    "    \n",
    "    return azimuth, zenith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e833e",
   "metadata": {
    "papermill": {
     "duration": 0.00659,
     "end_time": "2023-05-29T01:33:58.282347",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.275757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Weighted-Vector Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d6747c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:58.297666Z",
     "iopub.status.busy": "2023-05-29T01:33:58.296875Z",
     "iopub.status.idle": "2023-05-29T01:33:58.306619Z",
     "shell.execute_reply": "2023-05-29T01:33:58.305622Z"
    },
    "papermill": {
     "duration": 0.019832,
     "end_time": "2023-05-29T01:33:58.308992",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.289160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_vector_ensemble(angles, weight):\n",
    "    # Convert angle to vector\n",
    "    vec_models = list()\n",
    "    for angle in angles:\n",
    "        az, zen = angle\n",
    "        sa = np.sin(az)\n",
    "        ca = np.cos(az)\n",
    "        sz = np.sin(zen)\n",
    "        cz = np.cos(zen)\n",
    "        vec = np.stack([sz * ca, sz * sa, cz], axis=1)\n",
    "        vec_models.append(vec)\n",
    "    vec_models = np.array(vec_models)\n",
    "\n",
    "    # Weighted-mean\n",
    "    vec_mean = (weight.reshape((-1, 1, 1)) * vec_models).sum(axis=0) / weight.sum()\n",
    "    vec_mean /= np.sqrt((vec_mean**2).sum(axis=1)).reshape((-1, 1))\n",
    "\n",
    "    # Convert vector to angle\n",
    "    zenith = np.arccos(vec_mean[:, 2])\n",
    "    azimuth = np.arctan2(vec_mean[:, 1], vec_mean[:, 0])\n",
    "    azimuth[azimuth < 0] += 2 * np.pi\n",
    "    \n",
    "    return azimuth, zenith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55877f39",
   "metadata": {
    "papermill": {
     "duration": 0.007045,
     "end_time": "2023-05-29T01:33:58.322996",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.315951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Single event reader function\n",
    "\n",
    "- Pick-up important data points first\n",
    "    - Rank 3 (First)\n",
    "        - not aux, in valid time window\n",
    "    - Rank 2\n",
    "        - not aux, out of valid time window\n",
    "    - Rank 1\n",
    "        - aux, in valid time window\n",
    "    - Rank 0 (Last)\n",
    "        - aux, out of valid time window\n",
    "    - In each ranks, take pulses from highest charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f06606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:58.338415Z",
     "iopub.status.busy": "2023-05-29T01:33:58.338122Z",
     "iopub.status.idle": "2023-05-29T01:33:58.356688Z",
     "shell.execute_reply": "2023-05-29T01:33:58.355829Z"
    },
    "papermill": {
     "duration": 0.02888,
     "end_time": "2023-05-29T01:33:58.358925",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.330045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Placeholder\n",
    "open_batch_dict = dict()\n",
    "\n",
    "# Read single event from batch_meta_df\n",
    "def read_event(event_idx, batch_meta_df, pulse_count):\n",
    "    # Read metadata\n",
    "    batch_id, first_pulse_index, last_pulse_index = batch_meta_df.iloc[event_idx][[\"batch_id\", \"first_pulse_index\", \"last_pulse_index\"]].astype(\"int\")\n",
    "\n",
    "    # close past batch df\n",
    "    if batch_id - 1 in open_batch_dict.keys():\n",
    "        del open_batch_dict[batch_id - 1]\n",
    "\n",
    "    # open current batch df\n",
    "    if batch_id not in open_batch_dict.keys():\n",
    "        open_batch_dict.update({batch_id: pd.read_parquet(test_format.format(batch_id=batch_id))})\n",
    "    \n",
    "    batch_df = open_batch_dict[batch_id]\n",
    "    \n",
    "    # Read event\n",
    "    event_feature = batch_df[first_pulse_index:last_pulse_index + 1]\n",
    "    sensor_id = event_feature.sensor_id\n",
    "    \n",
    "    # Merge features into single structured array\n",
    "    dtype = [(\"time\", \"float32\"),\n",
    "             (\"charge\", \"float32\"),\n",
    "             (\"auxiliary\", \"float32\"),\n",
    "             (\"x\", \"float32\"),\n",
    "             (\"y\", \"float32\"),\n",
    "             (\"z\", \"float32\"),\n",
    "             (\"rank\", \"short\"),\n",
    "             (\"v\", \"float32\")]   \n",
    "    \n",
    "    # Create event_x\n",
    "    event_x = np.zeros(last_pulse_index - first_pulse_index + 1, dtype)\n",
    "    event_x[\"time\"] = event_feature.time.values - event_feature.time.min()\n",
    "    event_x[\"charge\"] = event_feature.charge.values\n",
    "    event_x[\"auxiliary\"] = event_feature.auxiliary.values\n",
    "    event_x[\"x\"] = sensor_geometry_df.x[sensor_id].values\n",
    "    event_x[\"y\"] = sensor_geometry_df.y[sensor_id].values\n",
    "    event_x[\"z\"] = sensor_geometry_df.z[sensor_id].values\n",
    "\n",
    "    # For long event, pick-up\n",
    "    if len(event_x) > pulse_count:\n",
    "        # Find valid time window\n",
    "        t_peak = event_x[\"time\"][event_x[\"charge\"].argmax()]\n",
    "        t_valid_min = t_peak - t_valid_length\n",
    "        t_valid_max = t_peak + t_valid_length\n",
    "        t_valid = (event_x[\"time\"] > t_valid_min) * (event_x[\"time\"] < t_valid_max)\n",
    "\n",
    "        # Rank\n",
    "        event_x[\"rank\"] = 2 * (1 - event_x[\"auxiliary\"]) + (t_valid)\n",
    "\n",
    "        # Sort by Rank and Charge (important goes to backward)\n",
    "        event_x = np.sort(event_x, order = [\"rank\", \"charge\"])\n",
    "\n",
    "        # pick-up from backward\n",
    "        event_x = event_x[-pulse_count:]\n",
    "\n",
    "        # Sort events by time \n",
    "        event_x = np.sort(event_x, order = \"time\")\n",
    "        \n",
    "        #calc vel\n",
    "        r=np.stack([event_x[\"x\"],event_x[\"y\"],event_x[\"z\"]],axis=1)\n",
    "        t=event_x[\"time\"][:,np.newaxis]\n",
    "        w=event_x[\"charge\"]\n",
    "        vel=distance(r,w)\n",
    "        event_x[\"v\"] = np.full(pulse_count, vel)\n",
    "    else:\n",
    "        # resort by time\n",
    "        event_x = np.sort(event_x, order=\"time\")\n",
    "\n",
    "        #calculate velocity\n",
    "        r=np.stack([event_x[\"x\"],event_x[\"y\"],event_x[\"z\"]],axis=1)\n",
    "        t=event_x[\"time\"][:,np.newaxis]\n",
    "        w=event_x[\"charge\"]\n",
    "        vel=distance(r,w)\n",
    "        event_x[\"v\"] = np.full(last_pulse_index - first_pulse_index + 1, vel)\n",
    "\n",
    "    return event_idx, len(event_x), event_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e88b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:58.374118Z",
     "iopub.status.busy": "2023-05-29T01:33:58.373821Z",
     "iopub.status.idle": "2023-05-29T01:33:58.381123Z",
     "shell.execute_reply": "2023-05-29T01:33:58.380153Z"
    },
    "papermill": {
     "duration": 0.017606,
     "end_time": "2023-05-29T01:33:58.383349",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.365743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distance(r,w):\n",
    "\n",
    "    def avg(p,w):\n",
    "        if len(p.shape)==1:\n",
    "            p=p.reshape(-1,1)\n",
    "        return np.average(p,weights=w,axis=0)\n",
    "    def SFF(x):\n",
    "        return x[:len(x)//2],x[len(x)//2:]\n",
    "    \n",
    "    s = avg(SFF(r)[0],SFF(w)[0])\n",
    "    t = avg(SFF(r)[0],SFF(w)[0])\n",
    "    v=np.linalg.norm(s-t,ord=2)\n",
    "    \n",
    "    \n",
    "    #v_est is the direction of travel\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e154512",
   "metadata": {
    "papermill": {
     "duration": 0.006597,
     "end_time": "2023-05-29T01:33:58.396813",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.390216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "673b0790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:58.412092Z",
     "iopub.status.busy": "2023-05-29T01:33:58.411307Z",
     "iopub.status.idle": "2023-05-29T01:33:58.495041Z",
     "shell.execute_reply": "2023-05-29T01:33:58.494224Z"
    },
    "papermill": {
     "duration": 0.093792,
     "end_time": "2023-05-29T01:33:58.497361",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.403569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Test Meta data\n",
    "test_meta_df = pq.read_table(home_dir + 'test_meta.parquet').to_pandas()\n",
    "batch_counts = test_meta_df.batch_id.value_counts().sort_index()\n",
    "\n",
    "batch_max_index = batch_counts.cumsum()\n",
    "batch_max_index[test_meta_df.batch_id.min() - 1] = 0\n",
    "batch_max_index = batch_max_index.sort_index()\n",
    "\n",
    "# Support Function\n",
    "def test_meta_df_spliter(batch_id):\n",
    "    return test_meta_df.loc[batch_max_index[batch_id - 1]:batch_max_index[batch_id] - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6959a",
   "metadata": {
    "papermill": {
     "duration": 0.006617,
     "end_time": "2023-05-29T01:33:58.511091",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.504474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Read test data and predict batchwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f393a8a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:33:58.526409Z",
     "iopub.status.busy": "2023-05-29T01:33:58.525763Z",
     "iopub.status.idle": "2023-05-29T01:34:18.570302Z",
     "shell.execute_reply": "2023-05-29T01:34:18.569171Z"
    },
    "papermill": {
     "duration": 20.055058,
     "end_time": "2023-05-29T01:34:18.572945",
     "exception": false,
     "start_time": "2023-05-29T01:33:58.517887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Batch IDs\n",
    "test_batch_ids = test_meta_df.batch_id.unique()\n",
    "\n",
    "# Submission Placeholders\n",
    "test_event_id = []\n",
    "test_azimuth = []\n",
    "test_zenith = []\n",
    "\n",
    "# Batch Loop\n",
    "for batch_id in test_batch_ids:\n",
    "    # Batch Meta DF\n",
    "    batch_meta_df = test_meta_df_spliter(batch_id)\n",
    "\n",
    "    # Set Pulses\n",
    "    test_x = np.zeros((len(batch_meta_df), pulse_count, feature_count), dtype = \"float16\")    \n",
    "    test_x[:, :, 2] = -1    \n",
    "\n",
    "    # Read Event Data\n",
    "    def read_event_local(event_idx):\n",
    "        return read_event(event_idx, batch_meta_df, pulse_count)\n",
    "    \n",
    "    # Multiprocess Events\n",
    "    iterator = range(len(batch_meta_df))\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        for event_idx, pulsecount, event_x in pool.map(read_event_local, iterator):\n",
    "            # Features\n",
    "            test_x[event_idx, :pulsecount, 0] = event_x[\"time\"]\n",
    "            test_x[event_idx, :pulsecount, 1] = event_x[\"charge\"]\n",
    "            test_x[event_idx, :pulsecount, 2] = event_x[\"auxiliary\"]\n",
    "            test_x[event_idx, :pulsecount, 3] = event_x[\"x\"]\n",
    "            test_x[event_idx, :pulsecount, 4] = event_x[\"y\"]\n",
    "            test_x[event_idx, :pulsecount, 5] = event_x[\"z\"]\n",
    "            test_x[event_idx, :pulsecount, 6] = event_x[\"v\"]\n",
    "    \n",
    "    del batch_meta_df\n",
    "    \n",
    "    # Normalize\n",
    "    test_x[:, :, 0] /= 1000  # time\n",
    "    test_x[:, :, 1] /= 300  # charge\n",
    "    test_x[:, :, 3:6] /= 600 # space\n",
    "    test_x[:, :, 6] /= 60\n",
    "        \n",
    "    # Predict\n",
    "    pred_angles = []\n",
    "    for model in models:\n",
    "        pred_model = model.predict(test_x, verbose=0)\n",
    "        az_model, zen_model = pred_to_angle(pred_model)\n",
    "        pred_angles.append((az_model, zen_model))\n",
    "    \n",
    "    # Get Predicted Azimuth and Zenith\n",
    "    pred_azimuth, pred_zenith = weighted_vector_ensemble(pred_angles, model_weights)\n",
    "    \n",
    "    # Get Event IDs\n",
    "    event_ids = test_meta_df.event_id[test_meta_df.batch_id == batch_id].values\n",
    "    \n",
    "    # Finalize \n",
    "    for event_id, azimuth, zenith in zip(event_ids, pred_azimuth, pred_zenith):\n",
    "        if np.isfinite(azimuth) and np.isfinite(zenith):\n",
    "            test_event_id.append(int(event_id))\n",
    "            test_azimuth.append(azimuth)\n",
    "            test_zenith.append(zenith)\n",
    "        else:\n",
    "            test_event_id.append(int(event_id))\n",
    "            test_azimuth.append(0.)\n",
    "            test_zenith.append(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd4c76",
   "metadata": {
    "papermill": {
     "duration": 0.006869,
     "end_time": "2023-05-29T01:34:18.587239",
     "exception": false,
     "start_time": "2023-05-29T01:34:18.580370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b33d8a58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:34:18.603487Z",
     "iopub.status.busy": "2023-05-29T01:34:18.603142Z",
     "iopub.status.idle": "2023-05-29T01:34:18.613933Z",
     "shell.execute_reply": "2023-05-29T01:34:18.612998Z"
    },
    "papermill": {
     "duration": 0.021155,
     "end_time": "2023-05-29T01:34:18.616092",
     "exception": false,
     "start_time": "2023-05-29T01:34:18.594937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and Save Submission.csv\n",
    "submission_df = pd.DataFrame({\"event_id\": test_event_id,\n",
    "                              \"azimuth\": test_azimuth,\n",
    "                              \"zenith\": test_zenith})\n",
    "submission_df = submission_df.sort_values(by = ['event_id'])\n",
    "submission_df.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf3940ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T01:34:18.632054Z",
     "iopub.status.busy": "2023-05-29T01:34:18.631145Z",
     "iopub.status.idle": "2023-05-29T01:34:18.650121Z",
     "shell.execute_reply": "2023-05-29T01:34:18.649172Z"
    },
    "papermill": {
     "duration": 0.029096,
     "end_time": "2023-05-29T01:34:18.652485",
     "exception": false,
     "start_time": "2023-05-29T01:34:18.623389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>zenith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2092</td>\n",
       "      <td>1.766849</td>\n",
       "      <td>1.568402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7344</td>\n",
       "      <td>3.473349</td>\n",
       "      <td>2.601744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9482</td>\n",
       "      <td>4.531773</td>\n",
       "      <td>1.516249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id   azimuth    zenith\n",
       "0      2092  1.766849  1.568402\n",
       "1      7344  3.473349  2.601744\n",
       "2      9482  4.531773  1.516249"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 56.409017,
   "end_time": "2023-05-29T01:34:22.597399",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-29T01:33:26.188382",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
